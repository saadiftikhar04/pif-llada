/home/si2356/.conda/envs/pif-llada/lib/python3.10/site-packages/transformers/utils/hub.py:110: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.
  warnings.warn(
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:02<00:12,  2.43s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:04<00:09,  2.43s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:07<00:07,  2.41s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:09<00:04,  2.38s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:12<00:02,  2.47s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:13<00:00,  2.08s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:13<00:00,  2.26s/it]
Traceback (most recent call last):
  File "/home/si2356/.conda/envs/pif-llada/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 399, in http_get
    import hf_transfer  # type: ignore[no-redef]
ModuleNotFoundError: No module named 'hf_transfer'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/scratch/si2356/pif-llada-minimal/run_pif_llada_ENHANCED.py", line 257, in <module>
    main()
  File "/scratch/si2356/pif-llada-minimal/run_pif_llada_ENHANCED.py", line 144, in main
    classifier = HarmBenchClassifier(device='cuda')
  File "/scratch/si2356/pif-llada-minimal/run_pif_llada_ENHANCED.py", line 26, in __init__
    self.tokenizer = AutoTokenizer.from_pretrained('cais/HarmBench-Llama-2-13b-cls')
  File "/home/si2356/.conda/envs/pif-llada/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py", line 1073, in from_pretrained
    tokenizer_config = get_tokenizer_config(pretrained_model_name_or_path, **kwargs)
  File "/home/si2356/.conda/envs/pif-llada/lib/python3.10/site-packages/transformers/models/auto/tokenization_auto.py", line 905, in get_tokenizer_config
    resolved_config_file = cached_file(
  File "/home/si2356/.conda/envs/pif-llada/lib/python3.10/site-packages/transformers/utils/hub.py", line 322, in cached_file
    file = cached_files(path_or_repo_id=path_or_repo_id, filenames=[filename], **kwargs)
  File "/home/si2356/.conda/envs/pif-llada/lib/python3.10/site-packages/transformers/utils/hub.py", line 567, in cached_files
    raise e
  File "/home/si2356/.conda/envs/pif-llada/lib/python3.10/site-packages/transformers/utils/hub.py", line 479, in cached_files
    hf_hub_download(
  File "/home/si2356/.conda/envs/pif-llada/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py", line 114, in _inner_fn
    return fn(*args, **kwargs)
  File "/home/si2356/.conda/envs/pif-llada/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1007, in hf_hub_download
    return _hf_hub_download_to_cache_dir(
  File "/home/si2356/.conda/envs/pif-llada/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1168, in _hf_hub_download_to_cache_dir
    _download_to_tmp_and_move(
  File "/home/si2356/.conda/envs/pif-llada/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 1735, in _download_to_tmp_and_move
    http_get(
  File "/home/si2356/.conda/envs/pif-llada/lib/python3.10/site-packages/huggingface_hub/file_download.py", line 401, in http_get
    raise ValueError(
ValueError: Fast download using 'hf_transfer' is enabled (HF_HUB_ENABLE_HF_TRANSFER=1) but 'hf_transfer' package is not available in your environment. Try `pip install hf_transfer`.
